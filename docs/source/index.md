# Pharia Studio SDK

Welcome to the Pharia Studio SDK ðŸ‘‹

The Pharia Studio SDK provides a comprehensive set of tools for evaluating and benchmarking Large Language Models (LLMs) with Studio applications. Formerly the `intelligence_layer/evaluation` package.

## Key Features

- ðŸ”— **Connectors**: Integration with Studio and Argilla platforms
- ðŸ“Š **Evaluation**: Comprehensive evaluation framework with aggregation and benchmarking
- ðŸŽ¯ **Benchmarking**: Tools for creating and running LLM benchmarks
- ðŸ“ˆ **Dataset Management**: Repository patterns for managing evaluation datasets

## Getting Started

- **New to the Pharia Studio SDK?** Start with the {doc}`02-core_concepts` to understand our architecture and key concepts.
- **Ready to build?** Check out the {doc}`01-quickstart` to get up and running in minutes.
- **Need detailed API information?** Explore our comprehensive {doc}`references` for all classes and methods.
- **Want to contribute?** See our [Contributing Guide](https://github.com/Aleph-Alpha/pharia-studio-sdk/blob/main/CONTRIBUTING.md) for details on how to set up the development environment and submit changes.

```{toctree}
:maxdepth: 4
:hidden:

01-quickstart
02-core_concepts
references
```

## Links

- **GitHub Repository**: [https://github.com/Aleph-Alpha/pharia-studio-sdk](https://github.com/Aleph-Alpha/pharia-studio-sdk)
- **PyPI Package**: [https://pypi.org/project/pharia-studio-sdk/](https://pypi.org/project/pharia-studio-sdk/)
